{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using L2 Normalization on Logistic Regression with SGD. I got 85.6% without, lets see how we can improve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  beta_regul = tf.placeholder(tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + beta_regul * tf.nn.l2_loss(weights)\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 19.372068\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 11.9%\n",
      "Minibatch loss at step 500: 3.218160\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 1000: 1.737247\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 1500: 1.311618\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 2000: 0.942690\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2500: 0.908568\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 3000: 0.639621\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 82.1%\n",
      "Test accuracy: 88.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 1e-3}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can tune the beta_regularization parameter using the valisdation set; lets do that to find the best beta_regul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "regul_val = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_val = []\n",
    "for beta_val in regul_val:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "      tf.global_variables_initializer().run()\n",
    "      print(\"Initialized\")\n",
    "      for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : beta_val}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "#        if (step % 500 == 0):\n",
    "#           print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "#           print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "#           print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "#             valid_prediction.eval(), valid_labels))\n",
    "      accuracy_val.append(accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEPCAYAAABLIROyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nt37HJCQHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f18400a2dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regul_val, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title('Test accuracy by regularization (logistic)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use L2 Regularization for the 1-layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_size = 28\n",
    "num_hidden_nodes = 1024\n",
    "num_labels = 10\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  beta_regul = tf.placeholder(tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  weights_1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  weights_2 = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  layer_1 = tf.nn.relu(tf.matmul(tf_train_dataset , weights_1) +biases_1)\n",
    "  logits = tf.matmul(layer_1, weights_2) + biases_2\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + beta_regul * (tf.nn.l2_loss(weights_1) +\n",
    "                                                                                                    tf.nn.l2_loss(weights_2))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights_2) + biases_2)\n",
    "  lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights_2) + biases_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n",
      "Initialized\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "regul_val = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_val = []\n",
    "for beta_val in regul_val:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "      tf.global_variables_initializer().run()\n",
    "      print(\"Initialized\")\n",
    "      for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : beta_val}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "#        if (step % 500 == 0):\n",
    "#           print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "#           print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "#           print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "#             valid_prediction.eval(), valid_labels))\n",
    "      accuracy_val.append(accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEPCAYAAABLIROyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1818065410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regul_val, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title('Test accuracy by regularization (logistic)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the NN with the best regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 919.338623\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 27.8%\n",
      "Minibatch loss at step 500: 230.767700\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 1000: 83.342163\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 82.7%\n",
      "Minibatch loss at step 1500: 30.824114\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 2000: 11.716578\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 2500: 4.700340\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 3000: 1.977905\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 92.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 2*1e-3}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 359.799744\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 29.4%\n",
      "Minibatch loss at step 0: 1253.651978\n",
      "Minibatch accuracy: 34.4%\n",
      "Validation accuracy: 37.9%\n",
      "Minibatch loss at step 0: 110.020088\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 72.2%\n",
      "Minibatch loss at step 0: 24.571081\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 0: 2.115981\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 0: 0.788447\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 0: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 74.4%\n",
      "Test accuracy: 80.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "num_of_batch = 3\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = step % num_of_batch\n",
    "    #offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 0}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 2 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tried running the overfitting model with dropout and L2 regularization. Get improvement from 66% to 74%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_size = 28\n",
    "num_hidden_nodes = 1024\n",
    "num_labels = 10\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  beta_regul = tf.placeholder(tf.float32)\n",
    "  \n",
    "  # Variables.\n",
    "  weights_1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "  weights_2 = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  layer_1 = tf.nn.relu(tf.matmul(tf_train_dataset , weights_1) +biases_1)\n",
    "  drop_1 = tf.nn.dropout(layer_1, 0.5)\n",
    "  logits = tf.matmul(drop_1, weights_2) + biases_2\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + beta_regul * (tf.nn.l2_loss(weights_1) +\n",
    "                                                                                                    tf.nn.l2_loss(weights_2))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights_2) + biases_2)\n",
    "  lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights_2) + biases_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 1138.038696\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 32.2%\n",
      "Minibatch loss at step 500: 237.283295\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 1000: 85.434135\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1500: 30.897116\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 2000: 11.768378\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 2500: 4.809886\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 3000: 2.073448\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 86.0%\n",
      "Test accuracy: 92.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "#num_of_batch = 3\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    #step = step % num_of_batch\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    #offset = step % num_of_batch\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels,beta_regul : 2*1e-3}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try a 3 layered neural net with drop out and L@ regularization. Also , Like suggested in the video s, I will try to use a low variance distribution to initialize the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "image_size = 28\n",
    "num_hidden_nodes_1 = 1024\n",
    "num_hidden_nodes_2 = 256\n",
    "num_hidden_nodes_3 = 128\n",
    "\n",
    "num_labels = 10\n",
    "beta_regul = 1e-3\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  #beta_regul = tf.placeholder(tf.float32)\n",
    "  global_step = tf.Variable(0)\n",
    "  \n",
    "  # Variables.\n",
    "  weights_1 = tf.Variable(\n",
    "        tf.truncated_normal([image_size * image_size, num_hidden_nodes_1],stddev=np.sqrt(2.0 / (image_size * image_size))))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_hidden_nodes_1]))\n",
    "  weights_2 = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes_1, num_hidden_nodes_2],stddev=np.sqrt(2.0 / (num_hidden_nodes_1))))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_hidden_nodes_2]))\n",
    "  weights_3 = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes_2, num_hidden_nodes_3],stddev=np.sqrt(2.0 / (num_hidden_nodes_2))))\n",
    "  biases_3 = tf.Variable(tf.zeros([num_hidden_nodes_3]))\n",
    "  weights_4 = tf.Variable(\n",
    "    tf.truncated_normal([num_hidden_nodes_3, num_labels],stddev=np.sqrt(2.0 / (num_hidden_nodes_3))))\n",
    "  biases_4 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  layer_1 = tf.nn.relu(tf.matmul(tf_train_dataset , weights_1) +biases_1)\n",
    "  drop_1 = tf.nn.dropout(layer_1, 0.5)\n",
    "  layer_2 = tf.nn.relu(tf.matmul(drop_1, weights_2) + biases_2)\n",
    "  drop_2 = tf.nn.dropout(layer_2,0.5)\n",
    "  layer_3 = tf.nn.relu(tf.matmul(drop_2, weights_3) + biases_3)\n",
    "  logits = tf.matmul(layer_3, weights_4) + biases_4\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + \\\n",
    "      beta_regul * (tf.nn.l2_loss(weights_1) + tf.nn.l2_loss(weights_2) + tf.nn.l2_loss(weights_3)+tf.nn.l2_loss(weights_4))\n",
    "  \n",
    "  # Optimizer.\n",
    "  learning_rate = tf.train.exponential_decay(0.5, global_step, 4000, 0.65, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1)\n",
    "  lay2_valid = tf.nn.relu(tf.matmul(lay1_valid, weights_2) + biases_2)\n",
    "  lay3_valid = tf.nn.relu(tf.matmul(lay2_valid, weights_3) + biases_3)\n",
    "\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(lay3_valid, weights_4) +biases_4)\n",
    "  lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1)\n",
    "  lay2_test = tf.nn.relu(tf.matmul(lay1_test, weights_2) + biases_2)\n",
    "  lay3_test = tf.nn.relu(tf.matmul(lay2_test, weights_3) + biases_3)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(lay3_test, weights_4) + biases_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.655272\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 19.0%\n",
      "Minibatch loss at step 1000: 1.023298\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 2000: 0.758131\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 3000: 0.609870\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 4000: 0.649047\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 5000: 0.563694\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 6000: 0.645673\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 7000: 0.498804\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 8000: 0.460752"
     ]
    }
   ],
   "source": [
    "num_steps = 20001\n",
    "#num_of_batch = 3\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    #step = step % num_of_batch\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    #offset = step % num_of_batch\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
